ID,Principle,Principle Name,Title,Description,Status,Frequency,Type,Keywords,URL,EU AI Act,ISO 42001,NIST AI RMF,OWASP Top 10,MITRE ATLAS,CSA AICM
A001,A,Data & Privacy,Establish input data policy,"Establish and communicate AI input data policies covering customer data usage for model training, inference processing, data retention periods, and customer rights",Mandatory,Every 12 months,Preventative,"Data Retention, Model Training Data, Opt-Out",/data-and-privacy/establish-data-use-policy,Article 11,"A.7.2, A.7.3",MEASURE 2.10,,"","DSP-11 to DSP-23"
A002,A,Data & Privacy,Establish output data policy,"Establish AI output ownership, usage, opt-out and deletion policies to customers and communicate these policies",Mandatory,Every 12 months,Preventative,"Data Ownership, Usage, Deletion, Consent, Opt-Out",/data-and-privacy/define-output-rights,,,,"","","DSP-16, DSP-08, STA-10"
A003,A,Data & Privacy,Limit AI agent data collection,"Implement safeguards to restrict AI agent data access to task-relevant information based on user roles and context",Mandatory,Every 12 months,Preventative,"Data Collection, Data Access, Agent Permissions, Access Permissions",/data-and-privacy/implement-contextual-data-safeguards,,"A.7.2, A.7.3",MAP 2.1,"LLM06:25, LLM08:25, LLM10:25",Data protection principles,"DSP-07, DSP-08, DSP-22, AIS-11, IAM-17, IAM-19, MDS-04"
A004,A,Data & Privacy,Protect IP & trade secrets,"Implement safeguards or technical controls to prevent AI systems from leaking company intellectual property or confidential information",Mandatory,Every 12 months,Preventative,"Intellectual Property, Confidential Information, Data Protections",/data-and-privacy/protect-ip-trade-secrets,Article 72,,,"LLM03:25, LLM05:25, LLM08:25",AML-M0020,"DSP-01, DSP-10, DSP-02, DSP-07, DSP-08, DSP-16, UEM-08, DSP-12"
A005,A,Data & Privacy,Prevent cross-customer data exposure,"Implement safeguards to prevent cross-customer data exposure when combining customer data from multiple sources",Mandatory,Every 12 months,Preventative,"Cross-Customer Data, Model Training, Data Rights",/data-and-privacy/prevent-cross-customer-data-exposure,,,MEASURE 2.10,"LLM02:25, LLM05:25, LLM08:25",,"I&S-06, DSP-22, UEM-08"
A006,A,Data & Privacy,Prevent PII leakage,"Establish safeguards to prevent personal data leakage through AI outputs",Mandatory,Every 12 months,Preventative,Personal Data Leakage,/data-and-privacy/prevent-pii-leakage,Article 72,,MEASURE 2.10,"LLM02:25, LLM05:25, LLM08:25",AML-M0020,"DSP-10, DSP-17, HRS-12, DSP-13, UEM-08"
A007,A,Data & Privacy,Prevent IP violations,"Implement safeguards and technical controls to prevent AI outputs from violating copyrights, trademarks, or other third-party intellectual property rights",Mandatory,Every 12 months,Preventative,"Intellectual Property, Copyright Protection",/data-and-privacy/prevent-ip-violations,,A.7.5,"GOVERN 6.1, MAP 4.1","LLM03:25, LLM05:25",AML-M0020,AIS-09
B001,B,Security,Third-party testing of adversarial robustness,"Implement adversarial testing program to validate system resilience against adversarial inputs and prompt injection attempts in line with adversarial threat taxonomy",Mandatory,Every 3 months,Preventative,"Adversarial Testing, Red Teaming, Prompt Injection, Jailbreak",/security/test-adversarial-robustness,,,"GOVERN 4.3, MEASURE 2.1, MEASURE 2.6, MEASURE 2.7","LLM01:25, LLM04:25, LLM05:25, LLM08:25","AML-M0003, AML-M0004","AIS-07, MDS-06, MDS-07, TVM-01 to TVM-13"
B002,B,Security,Detect adversarial input,"Implement monitoring capabilities to detect and respond to adversarial inputs and prompt injection attempts",Optional,Every 3 months,Detective,"Monitor, Adversarial, Jailbreak, Prompt Injection",/security/detect-adversarial-input,"Article 15, Article 72",,"GOVERN 1.5, MEASURE 2.4, MEASURE 2.7, MEASURE 3.1","LLM01:25, LLM08:25, LLM10:25","AML-M0003, AML-M0015, AML-M0024, AML-M0021","AIS-08, MDS-07, TVM-01, TVM-04, UEM-09, TVM-02, AIS-10, LOG-14"
B003,B,Security,Manage public release of technical details,"Implement controls to prevent over-disclosure of technical information about AI systems and organizational details that could enable adversarial targeting",Optional,Every 12 months,Preventative,"Public Disclosure, Open-Source, External Threats",/security/limit-technical-over-disclosure,,,,"LLM02:25, LLM07:25","AML-M0000, AML-M0001","AIS-09, AIS-15"
B004,B,Security,Prevent AI endpoint scraping,"Implement safeguards to prevent probing or scraping of external AI endpoints",Mandatory,Every 12 months,Preventative,"Scraping, Probing, Rate Limiting, Query Quotas, Zero Trust",/security/prevent-ai-endpoint-scraping,Article 15,,MEASURE 2.7,"LLM02:25, LLM05:25, LLM08:25, LLM10:25","AML-M0003, AML-M0004","AIS-10, UEM-01, UEM-05, UEM-09, UEM-10, UEM-14, TVM-06"
B005,B,Security,Implement real-time input filtering,"Deploy automated moderation tools for real-time input filtering",Optional,Every 12 months,Detective,"Prompt Injection, Jailbreak, Adversarial Input Protection",/security/implement-real-time-input-filtering,,,MEASURE 2.7,"LLM01:25, LLM04:25, LLM10:25","AML-M0015, AML-M0021","LOG-14, AIS-08, AIS-15"
B006,B,Security,Limit AI agent system access,"Implement safeguards to limit AI agent system access based on context and declared objectives",Mandatory,Every 12 months,Preventative,"Access Permissions, Agent Permissions",/security/enforce-contextual-access-controls,,,MAP 2.1,"LLM08:25, LLM10:25",,"AIS-11, IAM-19, DSP-07"
B007,B,Security,Enforce user access privileges to AI systems,"Establish and maintain user access controls and admin privileges for AI systems in line with policy",Mandatory,Every 3 months,Preventative,"Access Controls, Organizational Policy",/security/enforce-ai-access-privileges,,,,"LLM02:25, LLM06:25, LLM10:25","AML-M0005, AML-M0019","IAM, DSP, LOG controls"
B008,B,Security,Protect model deployment environment,"Implement security measures for AI model deployment environments including encryption, access controls and authorization",Mandatory,Every 12 months,Preventative,"Model Environment, Encryption, Access Controls",/security/protect-model-deployment-environment,Article 15,,,LLM07:25,"AML-M0005, AML-M0012, AML-M0019","AIS-06, AIS-14, CEK-01 to CEK-21, IAM-04, IAM-14, MDS-01, MDS-02, MDS-08, MDS-09, UEM-08, DSP-07"
B009,B,Security,Limit output over-exposure,"Implement output limitations and obfuscation techniques to safeguard against information leakage",Mandatory,Every 12 months,Preventative,"Output Obfuscation, Fidelity Reduction, Information Leakage, Adversarial Use, Response Filtering",/security/limit-output-over-exposure,,,MEASURE 2.10,"LLM02:25, LLM05:25, LLM08:25, LLM09:25",AML-M0002,AIS-09
C001,C,Safety,Define AI risk taxonomy,"Establish a risk taxonomy that categorizes risks within harmful, out-of-scope, and hallucinated outputs, tool calls, and other risks based on application-specific usage",Mandatory,Every 3 months,Preventative,"Risk Taxonomy, Severity Rating",/safety/define-ai-risk-taxonomy,Article 9,"A.5.2 to A.5.5, 4.1, 6.1.1 to 6.1.4, 8.2 to 8.4","GOVERN 1.3, GOVERN 1.4, GOVERN 4.2, MANAGE 1.2 to 1.4, MAP 1.5, MAP 5.1, MEASURE 1.1, MEASURE 2.10, MEASURE 2.11, MEASURE 3.1",,"","A&A-05, A&A-06, BCR-02, CEK-07, DSP-09, GRC-02, MDS-11, MDS-12, CCC-03"
C002,C,Safety,Conduct pre-deployment testing,"Conduct internal testing of AI systems before deployment across risk categories including high-risk, harmful, hallucinated, and out-of-scope outputs and tool calls for system changes requiring formal review or approval",Mandatory,Every 12 months,Preventative,"Internal Testing, Pre-Deployment Testing",/safety/conduct-pre-deployment-testing,"Article 9, Article 27","A.6.2.5, A.6.2.4","GOVERN 4.3, MANAGE 1.1, MAP 4.2, MEASURE 2.1, MEASURE 2.3, MEASURE 2.5, MEASURE 4.3",,AML-M0016,"AIS-05, AIS-06, AIS-07, AIS-12, CCC-02, AIS-04, TVM-05"
C003,C,Safety,Prevent harmful outputs,"Implement safeguards or technical controls to prevent harmful outputs including distressed outputs, angry responses, high-risk advice, offensive content, bias, and deception",Mandatory,Every 12 months,Preventative,"Harmful Outputs, Distressed, Angry, Advice, Offensive, Bias",/safety/prevent-harmful-outputs,Article 9,,MEASURE 2.11,"LLM05:25, LLM09:25",,"AIS-09, GRC-11, GRC-09, LOG-15, TVM-11"
C004,C,Safety,Prevent out-of-scope outputs,"Implement safeguards or technical controls to prevent out-of-scope outputs such as political discussion or healthcare advice that fall outside the AI system's intended use cases",Mandatory,Every 12 months,Preventative,"Out-of-Scope, Political Discussion, Technical Controls",/safety/prevent-out-of-scope-outputs,Article 72,,"MAP 2.2, MAP 3.4",LLM05:25,,"AIS-09, GRC-09, LOG-15, TVM-11"
C005,C,Safety,Prevent customer-defined high risk outputs,"Implement safeguards or technical controls to prevent additional high risk outputs as defined in risk taxonomy",Mandatory,Every 12 months,Preventative,"High-Risk Outputs, Risk Taxonomy, Technical Controls",/safety/prevent-other-high-risk-outputs,Article 9,,MANAGE 1.4,LLM05:25,,"GRC-09, LOG-15, TVM-11, STA-10"
C006,C,Safety,Prevent output vulnerabilities,"Implement safeguards to prevent security vulnerabilities in outputs from impacting users",Mandatory,Every 3 months,Preventative,"Harmful Outputs, Code Injection, Data Exfiltration",/safety/prevent-output-vulnerabilities,Article 72,,,LLM05:25,AML-M0020,"AIS-09, TVM-02, AIS-07"
C007,C,Safety,Flag high risk recommendations,"Implement an alerting system that flags high-risk recommendations for human review",Optional,Every 12 months,Preventative,"Human Review, Escalation",/safety/flag-high-risk-recommendations,,"A.6.1.2, A.9.3, A.9.2","GOVERN 3.2, MAP 3.5",,AML-M0020,GRC-15
C008,C,Safety,Monitor AI risk categories,"Implement monitoring of AI systems across risk categories",Optional,Every 12 months,Detective,"Monitoring, High-Risk Outputs",/safety/monitor-ai-risk-categories,Article 72,"A.5.4, A.6.2.6, A.9.4, 6.1.1 to 6.1.3, 8.2, 8.3, 9.1","GOVERN 1.5, MANAGE 3.1, MANAGE 4.1, MEASURE 2.4, MEASURE 4.3",,"","GRC-02, MDS-11, TVM-03, MDS-12, TVM-07"
C009,C,Safety,Enable real-time feedback and intervention,"Implement mechanisms to enable real-time user feedback collection and intervention mechanisms during AI system interactions",Optional,Every 3 months,Preventative,"Feedback, Intervention, User Control, Transparency",/safety/collect-real-time-feedback,Article 14,A.8.3,"GOVERN 3.2, MAP 3.5, MEASURE 3.3",,, GRC-15
C010,C,Safety,Third-party testing for harmful outputs,"Appoint expert third parties to evaluate system robustness to harmful outputs including distressed outputs, angry responses, high-risk advice, offensive content, bias, and deception at least every 3 months",Mandatory,Every 3 months,Preventative,"Harmful Outputs, Distressed, Angry, Advice, Offensive, Bias, Risk Severity, Toxigen, Third-Party Testing",/safety/3rd-party-testing-for-harmful-outputs,Article 9,A.6.2.4,"GOVERN 4.3, MANAGE 2.2, MEASURE 1.3, MEASURE 2.1, MEASURE 2.6, MEASURE 2.11, MEASURE 4.1, MEASURE 4.2",,"","GRC-11, A&A-02, TVM-06"
C011,C,Safety,Third-party testing for out-of-scope outputs,"Appoint qualified external assessors to evaluate system robustness against out-of-scope outputs (e.g., political discussion, healthcare advice) at minimum quarterly intervals",Mandatory,Every 3 months,Preventative,"Out-of-Scope, Political Discussion, Third-Party Testing",/safety/3rd-party-testing-for-out-of-scope-outputs,,A.6.2.4,"GOVERN 4.3, MANAGE 2.2, MAP 2.2, MEASURE 1.3, MEASURE 2.1, MEASURE 2.6, MEASURE 4.1, MEASURE 4.2",,"",""
C012,C,Safety,Third-party testing for customer-defined risk,"Appoint expert third-parties to evaluate system robustness to additional high-risk outputs as defined in risk taxonomy at least every 3 months",Mandatory,Every 3 months,Preventative,"High-Risk Outputs, Risk Taxonomy, Third-Party Testing",/safety/3rd-party-testing-for-other-risk,,A.6.2.4,"GOVERN 4.3, MANAGE 2.2, MEASURE 1.3, MEASURE 2.1, MEASURE 2.6, MEASURE 4.1, MEASURE 4.2",,"","A&A-02, TVM-06"
D001,D,Reliability,Prevent hallucinated outputs,"Implement safeguards or technical controls to prevent hallucinated outputs",Mandatory,Every 12 months,Preventative,"Hallucinations, Technical Controls",/reliability/prevent-hallucinated-outputs,,,MEASURE 2.5,"LLM05:25, LLM09:25",,"AIS-09, MDS-10, MDS-11"
D002,D,Reliability,Third-party testing for hallucinations,"Appoint qualified external assessors to evaluate hallucinated outputs at minimum quarterly intervals",Mandatory,Every 3 months,Preventative,"Hallucinations, Third-Party Testing",/reliability/3rd-party-testing-for-hallucinations,,A.6.2.4,"GOVERN 4.3, MANAGE 2.2, MEASURE 1.3, MEASURE 2.1, MEASURE 2.5, MEASURE 4.1, MEASURE 4.2",LLM09:25,,"AIS-09, AIS-05, MDS-06, MDS-07"
D003,D,Reliability,Restrict unsafe tool calls,"Implement safeguards or technical controls to prevent tool calls in AI systems from executing unauthorized actions, accessing restricted information, or making decisions beyond their intended scope",Mandatory,Every 12 months,Preventative,"Tool Calls, Tool Selection, Technical Controls",/reliability/restrict-unsafe-tool-calls,Article 72,,GOVERN 6.1,"LLM06:25, LLM08:25, LLM10:25","AML-M0004, AML-M0024","AIS-10, AIS-06, AIS-13, AIS-11, MDS-10, MDS-11, TVM-11, TVM-12"
D004,D,Reliability,Third-party testing of tool calls,"Appoint expert third parties to evaluate tool calls within AI systems, specifically assessing risks including unauthorized action execution, restricted information access, or decisions exceeding intended scope",Mandatory,Every 3 months,Preventative,"Tool Calls, Tool Selection, Third-Party Testing",/reliability/3rd-party-testing-of-tool-calls,,A.6.2.4,"GOVERN 6.1, GOVERN 4.3, MANAGE 2.2, MEASURE 1.3, MEASURE 2.1, MEASURE 2.6, MEASURE 4.1, MEASURE 4.2",LLM06:25,,AIS-05
E001,E,Accountability,AI failure plan for security breaches,"Document AI failure plan for AI privacy and security breaches assigning accountable owners and establishing notification and remediation with third-party support as needed",Mandatory,Every 12 months,Preventative,"Incident Response, Security, Privacy, Regulatory Deadlines",/accountability/ai-failure-plan-for-security-breaches,"Article 20, Article 73","A.8.4, A.8.5","GOVERN 4.3, MANAGE 1.3, MANAGE 4.3",,"","BCR-09, BCR-10, SEF-01 to SEF-09"
E002,E,Accountability,AI failure plan for harmful outputs,"Document a comprehensive response plan addressing harmful AI outputs causing significant customer harm, assigning accountability and establishing remediation procedures",Mandatory,Every 12 months,Preventative,"Incident Response, Emergency Response, Harmful Outputs, Hallucinations, Vendors",/accountability/ai-failure-plan-for-harmful-outputs,"Article 20, Article 73",A.8.4,"GOVERN 4.3, MANAGE 1.3, MANAGE 4.3",,"","BCR-09, BCR-10, SEF-09"
E003,E,Accountability,AI failure plan for hallucinations,"Document procedures addressing hallucinated AI outputs causing substantial customer financial loss, including accountability assignment and remediation processes",Mandatory,Every 12 months,Preventative,"Hallucinations, Incident Response, Customer Loss",/accountability/ai-failure-plan-for-hallucinations,"Article 20, Article 73",A.8.4,"GOVERN 4.3, MANAGE 1.3, MANAGE 4.3",,"","BCR-09, BCR-10, SEF-09"
E004,E,Accountability,Assign accountability,"Document which AI system changes across the development & deployment lifecycle require formal review or approval, assign a lead accountable for each, and document their approval with supporting evidence",Mandatory,Every 12 months,Preventative,"Decision Owners, Deployment",/accountability/assign-accountability,"Article 17, Article 18","A.3.2, A.4.6, A.6.2.2, A.10.2, 5.1, 5.3, 7.2","GOVERN 2.1, GOVERN 2.3, MAP 3.5, MEASURE 2.8",,AML-M0013,"AIS-01, AIS-04, CCC-01, CCC-03, CCC-05, CEK-02, GRC-06, MDS-09"
E005,E,Accountability,Assess cloud vs on-prem processing,"Establish criteria for selecting cloud provider, and circumstances for on-premises processing considering data sensitivity, regulatory requirements, security controls, and operational needs",Mandatory,Every 12 months,Preventative,"Deployment, Cloud Security, On-Premise Security, Data Residency",/accountability/assess-cloud-vs-on-prem-processing,,,MAP 4.2,LLM03:25,AML-M0017,"DCS-01 to DCS-15, AIS-05"
E006,E,Accountability,Conduct vendor due diligence,"Establish AI vendor due diligence processes for foundation and upstream model providers covering data handling, PII controls, security and compliance",Mandatory,Every 12 months,Preventative,"Vendor Due Diligence, Open-Source, Foundation Models, Upstream Models",/accountability/conduct-vendor-due-diligence,"Article 23, Article 24",A.10.3,MAP 4.2,LLM03:25,,"STA-01, STA-08 to STA-15"
E007,E,Accountability,Document system change approvals,"Define approval processes for material changes to AI systems (model versions, access controls, data sources) requiring formal review and sign-off",Optional,Every 12 months,Detective,"Approvals, Workflows",/accountability/document-system-change-approvals,"Article 17, Article 18","A.6.2.2, A.6.2.4, 6.3","GOVERN 2.1, GOVERN 2.3, MANAGE 1.1, MAP 3.5, MEASURE 2.8, MEASURE 4.3",,"","CCC-01, CCC-03, CCC-04, CCC-05, CCC-06, AIS-01"
E008,E,Accountability,Review internal processes,"Establish regular internal reviews of key processes and document review records and approvals",Mandatory,Every 12 months,Preventative,"Internal Reviews, Documentation",/accountability/review-internal-processes,Article 43,"A.3.3, A.2.3, A.2.4, 6.3, 7.5.2, 9.2.1, 9.2.2, 9.3.1, 9.3.2, 9.3.3","GOVERN 1.7, GOVERN 5.2, GOVERN 5.1, MANAGE 4.2, MEASURE 1.2, MEASURE 2.13",,"","A&A-02, A&A-03, A&A-05, A&A-06, GRC-03, IAM-03, IAM-08, LOG-07"
E009,E,Accountability,Monitor third-party access,"Implement systems to monitor third party access",Optional,Every 12 months,Preventative,"Access, Logins, Application",/accountability/monitor-3rd-party-access,Article 72,,"GOVERN 1.5, MANAGE 4.1","LLM03:25, LLM05:25, LLM06:25, LLM10:25",AML-M0024,"AIS-10, LOG-05, UEM-14, TVM-05"
E010,E,Accountability,Establish AI acceptable use policy,"Establish and implement a policy that defines prohibited AI usage, implements detection/monitoring tools, and provides user feedback when violations occur",Mandatory,Every 12 months,Preventative,"Acceptable Use, Breach",/accountability/establish-ai-acceptable-use-policy,,"A.2.2, A.9.2, A.9.4, A.2.4, A.9.3, 4.1, 4.3, 5.2","GOVERN 1.2, MAP 1.6, MAP 3.3, MAP 3.4, MEASURE 2.4",LLM10:25,,GRC-09
E011,E,Accountability,Record processing locations,"Document AI data processing locations",Mandatory,Every 12 months,Preventative,"Data Processing, Storage Location, Data Protections",/accountability/record-processing-locations,Article 11,A.7.5,GOVERN 1.6,,"","DSP-13, DSP-19, UEM-04"
E012,E,Accountability,Document regulatory compliance,"Document applicable AI laws and standards, required data protections, and strategies for compliance",Mandatory,Every 6 months,Preventative,"Regulatory, EU, NY, NIST, ISO, GDPR",/accountability/document-regulatory-compliance,"Articles 16, 18, 21, 22, 25, 26, 43, 44, 47, 48, 49","A.2.3, A.8.5, 10.2","GOVERN 1.1, GOVERN 1.7, MAP 1.1, MAP 4.1",,"","A&A-04, DSP-10, DSP-18, GRC-07, HRS-10"
E013,E,Accountability,Implement quality management system,"Establish a quality management system for AI systems proportionate to the size of the organization",Optional,Every 12 months,Preventative,"EU, Quality management, Regulatory",/accountability/implement-quality-management-system,"Articles 9, 10, 11, 12, 16, 17, 18, 19, 26, 43, 72, 73","A.5.2, A.6.2.7, A.5.3, A.5.4, A.4.2, 4.4, 6.1.4, 7.1","GOVERN 1.4, GOVERN 1.3",,"","AIS-01, AIS-03, BCR-02, GRC-02, GRC-10, MDS-02"
E014,E,Accountability,Share transparency reports,"Establish policies for sharing transparency reports with relevant stakeholders including regulators and customers",Optional,Every 12 months,Preventative,Transparency,/accountability/share-transparency-reports,Article 11,"A.6.2.7, A.8.2, A.8.5, 7.4","MANAGE 4.2, MANAGE 4.3, MAP 1.6, MAP 5.2, MEASURE 2.8, MEASURE 2.9, MEASURE 4.2",,"","GRC-14, TVM-09, TVM-10, A&A-06, LOG-13, LOG-10, SEF-05, SEF-07"
E015,E,Accountability,Log model activity,"Maintain logs of AI system processes, actions, and model outputs where permitted to support incident investigation, auditing, and explanation of AI system behavior",Mandatory,Every 12 months,Detective,"Explainability, Logs",/accountability/log-model-activity,"Article 12, Article 19",A.6.2.8,"MEASURE 2.4, MEASURE 2.8",LLM10:25,AML-M0024,"LOG-01 to LOG-15, MDS-10, SEF-05, SEF-07"
E016,E,Accountability,Implement AI disclosure mechanisms,"Implement clear disclosure mechanisms to inform users when they are interacting with AI systems rather than human operators",Mandatory,Every 12 months,Preventative,"Labelling, Transparency",/accountability/implement-ai-disclosure-mechanisms,"Article 13, Article 50",A.8.2,"MAP 2.2, MAP 3.4, MEASURE 2.8",,, GRC-15
E017,E,Accountability,Document system transparency policy,"Establish a system transparency policy and maintain a repository of model cards, datasheets, and interpretability reports for major systems",Optional,Every 12 months,Preventative,"Transparency, System Cards",/accountability/document-system-transparency-policy,Article 11,"A.4.2 to A.4.5, A.6.2.3, A.2.2, A.2.4, 4.3, 5.2","GOVERN 1.2, GOVERN 1.6, MAP 1.6, MEASURE 2.8, MEASURE 2.9, MEASURE 4.3",,"AML-M0023, AML-M0025","GRC-13, GRC-14, MDS-03 to MDS-05, STA-16, DSP-20"
F001,F,Society,Prevent AI cyber misuse,"Implement or document guardrails to prevent AI-enabled misuse for cyber attacks and exploitation",Mandatory,Every 12 months,Preventative,Cyber Attacks,/society/prevent-ai-cyber-misuse,,A.5.5,MEASURE 2.7,,"","GRC-02, GRC-09, GRC-10, GRC-12, TVM-11"
F002,F,Society,Prevent catastrophic misuse,"Implement or document guardrails to prevent AI-enabled catastrophic system misuse involving chemical, biological, radiological, or nuclear (CBRN) weapons development or mass harm scenarios",Mandatory,Every 12 months,Detective,"CBRN, Chemical, Bioweapon, Radioactive, Nuclear",/society/prevent-catastrophic-misuse,,A.5.5,,,"","GRC-02, GRC-09, GRC-10, GRC-12, TVM-11"
